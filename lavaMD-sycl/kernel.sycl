
//  THREAD PARAMETERS

int bx = item.get_group(0);    // get current horizontal block index (0-n)
int tx = item.get_local_id(0); // get current horizontal thread index (0-n)
int wtx = tx;

//  DO FOR THE NUMBER OF BOXES

if(bx<dim_cpu_number_boxes) {

  //  Extract input parameters

  // parameters
  fp a2 = 2*par_cpu.alpha*par_cpu.alpha;

  // home box
  int first_i;
  // (enable the line below only if wanting to use shared memory)

  // nei box
  int pointer;
  int k = 0;
  int first_j;
  int j = 0;
  // (enable the two lines below only if wanting to use shared memory)

  // common
  fp r2;
  fp u2;
  fp vij;
  fp fs;
  fp fxij;
  fp fyij;
  fp fzij;
  THREE_VECTOR d;

  //  Home box

  //  Setup parameters

  // home box - box parameters
  first_i = d_box_gpu[bx].offset;

  //  Copy to shared memory

  // (enable the section below only if wanting to use shared memory)
  // home box - shared memory
  while(wtx<NUMBER_PAR_PER_BOX){
    rA_shared[wtx] = d_rv_gpu[first_i+wtx];
    wtx = wtx + NUMBER_THREADS;
  }
  wtx = tx;

  // (enable the section below only if wanting to use shared memory)
  // synchronize threads  - not needed, but just to be safe for now
  item.barrier(sycl::access::fence_space::local_space);

  //  nei box loop

  // loop over nei boxes of home box
  for (k=0; k<(1+d_box_gpu[bx].nn); k++){

    //  nei box - get pointer to the right box

    if(k==0){
      pointer = bx;                          // set first box to be processed to home box
    }
    else{
      pointer = d_box_gpu[bx].nei[k-1].number;              // remaining boxes are nei boxes
    }

    //  Setup parameters

    // nei box - box parameters
    first_j = d_box_gpu[pointer].offset;

    // (enable the section below only if wanting to use shared memory)
    // nei box - shared memory
    while(wtx<NUMBER_PAR_PER_BOX){
      rB_shared[wtx] = d_rv_gpu[first_j+wtx];
      qB_shared[wtx] = d_qv_gpu[first_j+wtx];
      wtx = wtx + NUMBER_THREADS;
    }
    wtx = tx;

    // (enable the section below only if wanting to use shared memory)
    // synchronize threads because in next section each thread accesses data brought in by different threads here
    item.barrier(sycl::access::fence_space::local_space);

    //  Calculation

    // loop for the number of particles in the home box
    while(wtx<NUMBER_PAR_PER_BOX){

      auto fv = d_fv_gpu[first_i+wtx];
      auto rA = rA_shared[wtx];

      // loop for the number of particles in the current nei box
      for (j=0; j<NUMBER_PAR_PER_BOX; j++){
        auto rB = rB_shared[j];
        auto qB = qB_shared[j];

        r2 = rA.v + rB.v - DOT(rA, rB); 
        u2 = a2*r2;
        vij= sycl::exp(-u2);
        fs = 2*vij;
        d.x = rA.x  - rB.x;
        fxij=fs*d.x;
        d.y = rA.y  - rB.y;
        fyij=fs*d.y;
        d.z = rA.z  - rB.z;
        fzij=fs*d.z;

        fv.v += qB * vij;
        fv.x += qB * fxij;
        fv.y += qB * fyij;
        fv.z += qB * fzij;
      }

      d_fv_gpu[first_i+wtx] = fv;

      // increment work thread index
      wtx = wtx + NUMBER_THREADS;
    }

    // reset work index
    wtx = tx;

    // synchronize after finishing force contributions from current nei box not to cause conflicts when starting next box
    item.barrier(sycl::access::fence_space::local_space);

    //  Calculation END
  }
  //  nei box loop END
}
